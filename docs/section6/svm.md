# SVM {ignore=True}

[Toc]

特点： 二分类模型，label 为 -1 和 +1

## 线性可分 SVM

对于一个二分类问题，若数据集是线性可分的，那么我们可以找到这样一个超平面，使得数据的两个 label 分别位于平面两侧。

### 假设函数

$$
\hat { y } = \operatorname { sig } n \left( w ^ { T } x + b \right)
$$

### 损失函数

二分类的合页损失

$$
\max \left( 0,1 - y _ { i } \left( w \cdot x _ { i } + b \right) \right)
$$

### 函数间隔

函数间隔 $\gamma = \min_i \gamma _i = \min_i y_i(w^Tx_i+b)$

目标就是找到这样一个最大的间隔，使得所有点到超平面的距离都能大于这个间隔。

$w$ 其实就是这个超平面的法向量。因此几何间隔就是还要除以$w$的模长。

## 非线性可分-核技巧

少数点的存在使得全部数据非线性可分，可以加一些松弛。
但是如果完全非线性可分，那就需要使用核技巧。
