(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{261:function(t,s,a){t.exports=a.p+"assets/img/2019-06-15-08-19-20.b5770340.png"},262:function(t,s,a){t.exports=a.p+"assets/img/2019-06-15-08-32-46.bf24a815.png"},508:function(t,s,a){"use strict";a.r(s);var e=a(17),r=Object(e.a)({},(function(){var t=this,s=t.$createElement,e=t._self._c||s;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"cnn-ignore-true"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#cnn-ignore-true"}},[t._v("#")]),t._v(" CNN {ignore=true}")]),t._v(" "),e("p",[t._v("[TOC]")]),t._v(" "),e("p",[t._v("CNN 四大手段：局部连接／权值共享／池化操作／多层次结构")]),t._v(" "),e("p",[t._v("CNN 已经有了诸多成熟的架构")]),t._v(" "),e("p",[t._v("空洞卷积原理\nfocal loss")]),t._v(" "),e("h2",{attrs:{id:"基本原理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#基本原理"}},[t._v("#")]),t._v(" 基本原理")]),t._v(" "),e("h3",{attrs:{id:"卷积"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#卷积"}},[t._v("#")]),t._v(" 卷积")]),t._v(" "),e("p",[e("strong",[t._v("stride")]),t._v("\n每次移动卷积核的步长可以大于 1，可以减少输出的空间维度实现降维。 如下图所示的例子，它的 stride=2，输出的空间维度在每个维度上都大约减少了一半。 另一个角度来看，它相当于将下采样的功能集中到卷积层当中\n"),e("img",{attrs:{src:a(261),alt:""}})]),t._v(" "),e("p",[e("strong",[t._v("1-1 卷积")])]),t._v(" "),e("p",[e("strong",[t._v("卷积核分解")])]),t._v(" "),e("p",[e("img",{attrs:{src:a(262),alt:""}}),t._v("\n用两层的 3x3 卷积可以达到和一层 5x5 卷积相同的可视范围")]),t._v(" "),e("p",[e("strong",[t._v("深度分离卷积")]),t._v("\n深度分离卷积（Depthwise Separable Convolution）由 Xception 的作者 Chollet 提出， 将卷积层的两个功能——空间卷积核特征通道全连接完全分解为两个部分")]),t._v(" "),e("p",[e("strong",[t._v("分组卷积")]),t._v("\n分组卷积(Group Convolution)最早来自 AlexNet")]),t._v(" "),e("h2",{attrs:{id:"经典结构"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#经典结构"}},[t._v("#")]),t._v(" 经典结构")]),t._v(" "),e("h3",{attrs:{id:"_1998-lenet-5"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1998-lenet-5"}},[t._v("#")]),t._v(" 1998-LeNet-5")]),t._v(" "),e("p",[t._v("被誉为是卷积神经网络的“Hello Word”")]),t._v(" "),e("h3",{attrs:{id:"_2012-alexnet"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2012-alexnet"}},[t._v("#")]),t._v(" 2012-AlexNet")]),t._v(" "),e("p",[t._v("Hinton 团队的 AlexNet 可以算是开启本轮深度学习浪潮的开山之作了。由于 AlexNet 在 ImageNet LSVRC-2012（Large Scale Visual Recognition Competition）赢得第一名，并且错误率只有 15.3%（第二名是 26.2%），引起了巨大的反响。相比较之前的深度学习网络结构，AlexNet 主要的变化在于激活函数采用了 Relu、使用 Dropout 代替正则降低过拟合等。")]),t._v(" "),e("p",[t._v("共有 8 层网络。\n采用 ReLU 主要考虑的是加快训练速度。\nDropout 大约使得收敛的迭代次数翻倍了")]),t._v(" "),e("h3",{attrs:{id:"_2014-vgg-net"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2014-vgg-net"}},[t._v("#")]),t._v(" 2014-VGG-Net")]),t._v(" "),e("p",[t._v("Visual Geometry Group")]),t._v(" "),e("blockquote",[e("p",[t._v("问： 如何设计网络结构以提高精度？\n答： 使用较小的卷积核，更深的网络层")])]),t._v(" "),e("blockquote",[e("p",[t._v("It's not complicated, it's just a lot of it - 费曼描述宇宙")])]),t._v(" "),e("p",[t._v("所有的卷积核大小都是 3x3 的")]),t._v(" "),e("p",[t._v("采用 Caffe 作为深度学习框架并开源了模型。")]),t._v(" "),e("h3",{attrs:{id:"_2014-googlenet"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2014-googlenet"}},[t._v("#")]),t._v(" 2014-googleNet")]),t._v(" "),e("p",[e("a",{attrs:{href:"http://arxiv.org/pdf/1409.4842.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Going deeper with convolutions"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("提出了 Inception 结构")]),t._v(" "),e("h3",{attrs:{id:"_2015-resnet"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2015-resnet"}},[t._v("#")]),t._v(" 2015-ResNet")]),t._v(" "),e("p",[t._v("论文 "),e("code",[t._v("Deep Residual Learning for Image Recognition")]),t._v(" 提出的残差网络，荣获 CVPR2016 年度最佳论文。")]),t._v(" "),e("p",[t._v("自从深度神经网络在ImageNet大放异彩之后，后来问世的深度神经网络就朝着网络层数越来越深的方向发展。直觉上我们不难得出结论：增加网络深度后，网络可以进行更加复杂的特征提取，因此更深的模型可以取得更好的结果。")]),t._v(" "),e("p",[t._v("但事实并非如此，人们发现随着网络深度的增加，模型精度并不总是提升，并且这个问题显然不是由过拟合（overfitting）造成的，因为 "),e("strong",[t._v("网络加深后不仅测试误差变高了，它的训练误差竟然也变高了")]),t._v("。作者提出，这可能是因为更深的网络会伴随梯度消失/爆炸问题，从而阻碍网络的收敛。作者将这种加深网络深度但网络性能却下降的现象称为退化问题（degradation problem）")]),t._v(" "),e("p",[t._v("网络增加了一个跳跃连接，也有说是加飞线")]),t._v(" "),e("p",[t._v("设第 "),e("span",{staticClass:"katex"},[e("span",{staticClass:"katex-mathml"},[e("math",[e("semantics",[e("mrow",[e("mi",[t._v("l")])],1),e("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("l")])],1)],1)],1),e("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[e("span",{staticClass:"strut",staticStyle:{height:"0.69444em"}}),e("span",{staticClass:"strut bottom",staticStyle:{height:"0.69444em","vertical-align":"0em"}}),e("span",{staticClass:"base textstyle uncramped"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")])])])]),t._v(" 层输入向量为 "),e("span",{staticClass:"katex"},[e("span",{staticClass:"katex-mathml"},[e("math",[e("semantics",[e("mrow",[e("msub",[e("mi",[t._v("x")]),e("mi",[t._v("l")])],1)],1),e("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("x_l")])],1)],1)],1),e("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[e("span",{staticClass:"strut",staticStyle:{height:"0.43056em"}}),e("span",{staticClass:"strut bottom",staticStyle:{height:"0.58056em","vertical-align":"-0.15em"}}),e("span",{staticClass:"base textstyle uncramped"},[e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit"},[t._v("x")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle cramped"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])]),t._v("，那么输出变为")]),t._v(" "),e("p",[e("span",{staticClass:"katex-display"},[e("span",{staticClass:"katex"},[e("span",{staticClass:"katex-mathml"},[e("math",[e("semantics",[e("mrow",[e("msub",[e("mi",[t._v("y")]),e("mrow",[e("mi",[t._v("l")])],1)],1),e("mo",[t._v("=")]),e("mi",[t._v("F")]),e("mrow",[e("mo",{attrs:{fence:"true"}},[t._v("(")]),e("msub",[e("mi",[t._v("x")]),e("mrow",[e("mi",[t._v("l")])],1)],1),e("mo",{attrs:{separator:"true"}},[t._v(";")]),e("msub",[e("mi",[t._v("W")]),e("mrow",[e("mi",[t._v("l")])],1)],1),e("mo",{attrs:{fence:"true"}},[t._v(")")])],1),e("mo",[t._v("+")]),e("msub",[e("mi",[t._v("x")]),e("mrow",[e("mi",[t._v("l")])],1)],1)],1),e("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("y _ { l } = F \\left( x _ { l } ; W _ { l } \\right) + x _ { l }\n")])],1)],1)],1),e("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[e("span",{staticClass:"strut",staticStyle:{height:"0.75em"}}),e("span",{staticClass:"strut bottom",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),e("span",{staticClass:"base displaystyle textstyle uncramped"},[e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.03588em"}},[t._v("y")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.03588em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle cramped"},[e("span",{staticClass:"mord scriptstyle cramped"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")])])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),e("span",{staticClass:"mrel"},[t._v("=")]),e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")]),e("span",{staticClass:"minner displaystyle textstyle uncramped"},[e("span",{staticClass:"style-wrap reset-textstyle textstyle uncramped",staticStyle:{top:"0em"}},[t._v("(")]),e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit"},[t._v("x")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle cramped"},[e("span",{staticClass:"mord scriptstyle cramped"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")])])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),e("span",{staticClass:"mpunct"},[t._v(";")]),e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.13889em"}},[t._v("W")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"-0.13889em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle cramped"},[e("span",{staticClass:"mord scriptstyle cramped"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")])])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])]),e("span",{staticClass:"style-wrap reset-textstyle textstyle uncramped",staticStyle:{top:"0em"}},[t._v(")")])]),e("span",{staticClass:"mbin"},[t._v("+")]),e("span",{staticClass:"mord"},[e("span",{staticClass:"mord mathit"},[t._v("x")]),e("span",{staticClass:"vlist"},[e("span",{staticStyle:{top:"0.15em","margin-right":"0.05em","margin-left":"0em"}},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),e("span",{staticClass:"reset-textstyle scriptstyle cramped"},[e("span",{staticClass:"mord scriptstyle cramped"},[e("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")])])])]),e("span",{staticClass:"baseline-fix"},[e("span",{staticClass:"fontsize-ensurer reset-size5 size5"},[e("span",{staticStyle:{"font-size":"0em"}},[t._v("​")])]),t._v("​")])])])])])])])]),t._v(" "),e("p",[t._v("可以看到，非线性变化实际上是在拟合残差,这也是为什么称作残差连接的原因")]),t._v(" "),e("p",[t._v("为了降低网络参数量和计算复杂度，作者引入了 "),e("code",[t._v("BotteleNeck")]),t._v(" 结构，在超过 50 层的网络中使用 BottleNeck 来代替原始的残差块")]),t._v(" "),e("p",[t._v("理论上来讲，残差网络（ResNet）已经构造出一种结构，可以不断地增加网络的层数来提高模型的准确率，虽然会使得计算复杂度越来越高。它证实了我们可以很好地优化任意深度的网络。要知道，在那之前，在网络层数达到一定深度后，继续增加反而会使得模型的效果下降！因此，残差网络将人们对深度的探索基本上下了一个定论，"),e("strong",[t._v("没有最深，只有更深")]),t._v("，就看你资源够不够！")]),t._v(" "),e("p",[e("a",{attrs:{href:"http://arxiv.org/pdf/1409.1556.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("very deep convolutional networks for large-scale image recognition"),e("OutboundLink")],1)]),t._v(" "),e("h4",{attrs:{id:"resnet-变种"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#resnet-变种"}},[t._v("#")]),t._v(" ResNet 变种")]),t._v(" "),e("h3",{attrs:{id:"其他"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#其他"}},[t._v("#")]),t._v(" 其他")]),t._v(" "),e("ul",[e("li",[e("p",[t._v("OverFeat")]),t._v(" "),e("p",[e("a",{attrs:{href:"http://arxiv.org/pdf/1312.6229.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks"),e("OutboundLink")],1)])]),t._v(" "),e("li",[e("p",[t._v("R-CNN")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://github.com/rbgirshick/rcnn",target:"_blank",rel:"noopener noreferrer"}},[t._v("R-CNN: Regions with Convolutional Neural Network Features"),e("OutboundLink")],1)])])]),t._v(" "),e("ul",[e("li",[e("p",[t._v("ShCNN")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://papers.nips.cc/paper/5774-shepard-convolutional-neural-networks.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("Shepard Convolutional Neural Networks by Jimmy SJ. Ren, et al., NIPS 2015"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("SenseTime(商汤科技，一家专注于计算机视觉和深度学习原创技术的中国公司)研究人员出品，"),e("a",{attrs:{href:"https://github.com/jimmy-ren/vcnn_double-bladed/tree/master/applications/Shepard_CNN",target:"_blank",rel:"noopener noreferrer"}},[t._v("代码在此"),e("OutboundLink")],1),t._v("。可用在超分辨率重建，图像修补等。")])]),t._v(" "),e("li",[e("p",[t._v("PlaNet")]),t._v(" "),e("p",[e("a",{attrs:{href:"http://arxiv.org/abs/1602.05314",target:"_blank",rel:"noopener noreferrer"}},[t._v("PlaNet - Photo Geolocation with Convolutional Neural Networks"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("谷歌的工作，仅用图片的像素来定位图片位置")])])]),t._v(" "),e("h3",{attrs:{id:"时间卷积网络（temporal-convolutional-nets-tcns）"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#时间卷积网络（temporal-convolutional-nets-tcns）"}},[t._v("#")]),t._v(" 时间卷积网络（Temporal Convolutional Nets, TCNs）")]),t._v(" "),e("p",[t._v("ByteNet, FairSeq")]),t._v(" "),e("ul",[e("li",[t._v("An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling")])]),t._v(" "),e("h2",{attrs:{id:"octconv"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#octconv"}},[t._v("#")]),t._v(" OctConv")]),t._v(" "),e("h2",{attrs:{id:"dorefa-net"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#dorefa-net"}},[t._v("#")]),t._v(" Dorefa-Net")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://arxiv.org/abs/1606.06160",target:"_blank",rel:"noopener noreferrer"}},[t._v("论文地址"),e("OutboundLink")],1)])])}),[],!1,null,null,null);s.default=r.exports}}]);