(window.webpackJsonp=window.webpackJsonp||[]).push([[123],{552:function(t,a,i){"use strict";i.r(a);var r=i(17),e=Object(r.a)({},(function(){var t=this,a=t.$createElement,i=t._self._c||a;return i("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[i("h1",{attrs:{id:"_2019-论文精读-ignore-true"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2019-论文精读-ignore-true"}},[t._v("#")]),t._v(" 2019 论文精读 {ignore=true}")]),t._v(" "),i("h3",{staticStyle:{color:"inherit","line-height":"inherit","margin-top":"1.6em","margin-bottom":"1.6em","font-weight":"bold","border-bottom":"2px solid rgb(239, 112, 96)","font-size":"1.3em"}},[i("span",{staticStyle:{"font-size":"inherit","line-height":"inherit",display:"inline-block","font-weight":"normal",background:"rgb(239, 112, 96)",color:"rgb(255, 255, 255)",padding:"3px 10px 1px","border-top-right-radius":"3px","border-top-left-radius":"3px","margin-right":"3px"}},[t._v("论文\n")])]),t._v(" "),i("section",{staticStyle:{"margin-bottom":"-10px","margin-left":"-8px","max-width":"100%",width:"18px",height:"18px","border-top":"8px solid rgb(54, 85, 173)","border-left":"8px solid rgb(54, 65, 173)","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}}),t._v(" "),i("section",{staticStyle:{"max-width":"100%",background:"rgb(247, 247, 247)","box-sizing":"border-box !important","overflow-wrap":"break-word !important"},attrs:{"data-bgopacity":"50%"}},[i("section",{staticStyle:{padding:"1em","max-width":"100%","letter-spacing":"1.5px","line-height":"1.75em","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}},[i("p",{staticStyle:{color:"rgb(63, 63, 63)","font-size":"15px","max-width":"100%","min-height":"1em","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}},[i("span",{staticStyle:{color:"rgb(11, 0, 34)","font-size":"15px"}},[t._v("Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity\n")])]),t._v(" "),i("span",{staticClass:"author-span"},[t._v("Hulu-陈拉明 •")]),t._v(" "),i("span",{staticClass:"author-span"},[t._v("2018-NIPS")]),t._v(" "),i("p",{staticStyle:{color:"rgb(63, 63, 63)","font-size":"15px","max-width":"100%","min-height":"1em","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}},[i("span",{staticStyle:{color:"rgb(11, 35, 234)","font-size":"14px"}})])])]),i("section",{staticStyle:{"margin-top":"-10px","margin-left":"8px","max-width":"100%","justify-content":"flex-end",display:"flex","box-sizing":"border-box !important","overflow-wrap":"break-word !important"},attrs:{"data-width":"100%"}},[i("section",{staticStyle:{"max-width":"100%",width:"18px",height:"18px","border-bottom":"8px solid rgb(54, 65, 173)","border-right":"8px solid rgb(54, 65, 173)","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}},[i("br")])]),t._v(" "),i("h3",{attrs:{id:"背景概念"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#背景概念"}},[t._v("#")]),t._v(" 背景概念")]),t._v(" "),i("h4",{attrs:{id:"行列式点过程"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#行列式点过程"}},[t._v("#")]),t._v(" 行列式点过程")]),t._v(" "),i("p",[t._v("DPP ("),i("code",[t._v("Determinantal Point Process")]),t._v(") 行列式点过程")]),t._v(" "),i("blockquote",[i("p",[t._v("DPP 是一种性能较高的概率模型。DPP 将复杂的概率计算转换成简单的行列式计算，并通过核矩阵的行列式计算每一个子集的概率。DPP 不仅减少了计算量，而且提高了运行效率，在图片分割、文本摘要和商品推荐系统中均具有较成功的应用。")])]),t._v(" "),i("p",[t._v("行列式计算简单吗？")]),t._v(" "),i("p",[t._v("DPP 通过最大后验概率估计，找到商品集中相关性和多样性最大的子集，从而作为推荐给用户的商品集。")]),t._v(" "),i("p",[t._v("DPP 可以理解为一种抽样方法:")]),t._v(" "),i("p",[t._v("两个元素作为子集被抽取的概率不仅和单一元素被抽取的概率相关,还和这两个元素的相关性有关。单一元素被选择的概率越大，同时元素之间的相似度越低，则这个集合被选择的概率越高。")]),t._v(" "),i("h4",{attrs:{id:"多样性的衡量"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#多样性的衡量"}},[t._v("#")]),t._v(" 多样性的衡量")]),t._v(" "),i("p",[t._v("Exploration 主要有三个方面：")]),t._v(" "),i("ol",[i("li",[i("p",[t._v("覆盖度：被推荐给用户的内容占全部内容的比例应该较高，特别是新的内容能够有机会展现给用户。")])]),t._v(" "),i("li",[i("p",[t._v("惊喜：推荐的内容并不与用户之前的行为明显相关，但又是用户所喜欢的。这能很大程度提升用户体验，但却难以给出衡量指标。")])]),t._v(" "),i("li",[i("p",[t._v("多样性：在短时间内不要过多地向同一用户推荐同一类型的内容，而是混合各种类型的内容推荐给用户。")])])]),t._v(" "),i("p",[t._v("如何衡量多样性？")]),t._v(" "),i("ol",[i("li",[t._v("Temporal Diversity ( 时间的多样性 )\n在固定的时间间隔内推荐"),i("em",[t._v("不同类")]),t._v("的内容的个数\n策略： 跨类别推荐；时间衰减；Impression discount ( 印象折扣 ) ，统计所有推荐给用户的内容中哪些是用户没有观看")]),t._v(" "),i("li",[t._v("Spatial Diversity ( 空间的多样性 )\n单个推荐列表中物品之间的差异程度，可以通过计算在同一个推荐 list 中两两 Item 之间的相似度的平均值来进行衡量。")])]),t._v(" "),i("p",[t._v("一个用户很喜欢看漫威的电影，也喜欢看一些文艺类的电影，其中用户观看漫威的电影比较多一些，看文艺类的电影少一些，那么推荐系统很容易造成推荐的时候只推荐漫威类的电影。")]),t._v(" "),i("h3",{attrs:{id:"论文主要内容"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#论文主要内容"}},[t._v("#")]),t._v(" 论文主要内容")]),t._v(" "),i("p",[t._v("直接优化求解哪个子集的行列式最大，这是 NP hard 的问题，因此，陈拉明团队则利用贪婪算法，提出了一种能加速行列式点过程推理过程的方法： 即将该问题转化为一种贪婪的形式。")]),t._v(" "),i("p",[t._v("在模型求解时，行列式的复杂度其实是非常高的（一般是行列式大小的三次方），现时不适用于于线上对性能有高要求的场景。论文中对此也做了改进：利用 Cholesky 分解，将行列式的计算转化为下三角行列式这种简单的形式（计算复杂度能降低到二次方）。进一步，用增量的方式更新，将每次迭代的复杂度进一步降低到一次方。")]),t._v(" "),i("h3",{staticStyle:{color:"inherit","line-height":"inherit","margin-top":"1.6em","margin-bottom":"1.6em","font-weight":"bold","border-bottom":"2px solid rgb(239, 112, 96)","font-size":"1.3em"}},[i("span",{staticStyle:{"font-size":"inherit","line-height":"inherit",display:"inline-block","font-weight":"normal",background:"rgb(239, 112, 96)",color:"rgb(255, 255, 255)",padding:"3px 10px 1px","border-top-right-radius":"3px","border-top-left-radius":"3px","margin-right":"3px"}},[t._v("论文\n")])]),t._v(" "),i("section",{staticStyle:{"margin-bottom":"-10px","margin-left":"-8px","max-width":"100%",width:"18px",height:"18px","border-top":"8px solid rgb(54, 85, 173)","border-left":"8px solid rgb(54, 65, 173)","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}}),t._v(" "),i("section",{staticStyle:{"max-width":"100%",background:"rgb(247, 247, 247)","box-sizing":"border-box !important","overflow-wrap":"break-word !important"},attrs:{"data-bgopacity":"50%"}},[i("section",{staticStyle:{padding:"1em","max-width":"100%","letter-spacing":"1.5px","line-height":"1.75em","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}},[i("p",{staticStyle:{color:"rgb(63, 63, 63)","font-size":"15px","max-width":"100%","min-height":"1em","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}},[i("span",{staticStyle:{color:"rgb(11, 0, 34)","font-size":"15px"}},[t._v("Focal Loss for Dense Object Detection")])]),t._v(" "),i("span",{staticClass:"author-span"},[t._v("ICCV2017 | paper-author")]),t._v(" "),i("p",{staticStyle:{color:"rgb(63, 63, 63)","font-size":"15px","max-width":"100%","min-height":"1em","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}},[i("span",{staticStyle:{color:"rgb(11, 35, 234)","font-size":"14px"}})])])]),t._v(" "),i("section",{staticStyle:{"margin-top":"-10px","margin-left":"8px","max-width":"100%","justify-content":"flex-end",display:"flex","box-sizing":"border-box !important","overflow-wrap":"break-word !important"},attrs:{"data-width":"100%"}},[i("section",{staticStyle:{"max-width":"100%",width:"18px",height:"18px","border-bottom":"8px solid rgb(54, 65, 173)","border-right":"8px solid rgb(54, 65, 173)","box-sizing":"border-box !important","overflow-wrap":"break-word !important"}},[i("br")])]),t._v(" "),i("h3",{attrs:{id:"论文内容"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#论文内容"}},[t._v("#")]),t._v(" 论文内容")]),t._v(" "),i("p",[t._v("Focal Loss 的引入主要是为了解决难易样本数量不平衡的问题。\n注意，难易样本数量不平衡"),i("strong",[t._v("区别于正负样本数量不平衡")])]),t._v(" "),i("p",[t._v("正负样本不平衡的问题，可以在 交叉熵损失的前面加上一个参数 "),i("span",{staticClass:"katex"},[i("span",{staticClass:"katex-mathml"},[i("math",[i("semantics",[i("mrow",[i("mi",[t._v("α")])],1),i("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\alpha")])],1)],1)],1),i("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[i("span",{staticClass:"strut",staticStyle:{height:"0.43056em"}}),i("span",{staticClass:"strut bottom",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),i("span",{staticClass:"base textstyle uncramped"},[i("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.0037em"}},[t._v("α")])])])])]),t._v(" "),i("p",[t._v("对难易问题，一个简单的思想：把高置信度(p)样本的损失再降低一些不就好了吗！")]),t._v("\nF L=\\left \\\\{\\begin{array}{ccc}{-(1-p)^{\\gamma} \\log (p),} & {\\text { if }} & {y=1} \\\\\\ {-p^{\\gamma} \\log (1-p),} & {\\text { if }} & {y=0}\\end{array}\\right.\n\n"),i("p",[t._v("结合二者，最终的 Focal Loss 形式如下")]),t._v("\nF L=\\left\\\\{\\begin{aligned}-\\alpha(1-p)^{\\gamma} \\log (p), & \\text { if } & y=1 \\\\\\-(1-\\alpha) p^{\\gamma} \\log (1-p), & \\text { if } & y=0 \\end{aligned}\\right.\n\n"),i("p",[t._v("实验表明"),i("span",{staticClass:"katex"},[i("span",{staticClass:"katex-mathml"},[i("math",[i("semantics",[i("mrow",[i("mi",[t._v("γ")])],1),i("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\gamma")])],1)],1)],1),i("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[i("span",{staticClass:"strut",staticStyle:{height:"0.43056em"}}),i("span",{staticClass:"strut bottom",staticStyle:{height:"0.625em","vertical-align":"-0.19444em"}}),i("span",{staticClass:"base textstyle uncramped"},[i("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.05556em"}},[t._v("γ")])])])]),t._v(" 取 2, "),i("span",{staticClass:"katex"},[i("span",{staticClass:"katex-mathml"},[i("math",[i("semantics",[i("mrow",[i("mi",[t._v("α")])],1),i("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\alpha")])],1)],1)],1),i("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[i("span",{staticClass:"strut",staticStyle:{height:"0.43056em"}}),i("span",{staticClass:"strut bottom",staticStyle:{height:"0.43056em","vertical-align":"0em"}}),i("span",{staticClass:"base textstyle uncramped"},[i("span",{staticClass:"mord mathit",staticStyle:{"margin-right":"0.0037em"}},[t._v("α")])])])]),t._v(" 取 0.25 的时候效果最佳。")]),t._v(" "),i("h3",{attrs:{id:"后续延伸"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#后续延伸"}},[t._v("#")]),t._v(" 后续延伸")]),t._v(" "),i("p",[t._v('GHM (gradient harmonizing mechanism) 发表于 “Gradient Harmonized Single-stage Detector", AAAI2019，是基于 Focal loss 的改进。')])])}),[],!1,null,null,null);a.default=e.exports}}]);