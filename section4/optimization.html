<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>最优化 {ignore=true} | Lancezhange Vuepress Book</title>
    <meta name="description" content="Learner">
    <meta name="generator" content="VuePress 1.3.1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
  <link rel="stylesheet" href="/grocery_store/css/index.css">
    
    <link rel="preload" href="/grocery_store/assets/css/0.styles.892fb305.css" as="style"><link rel="preload" href="/grocery_store/assets/js/app.47d3b9e2.js" as="script"><link rel="preload" href="/grocery_store/assets/js/3.e15ba04f.js" as="script"><link rel="preload" href="/grocery_store/assets/js/14.c8cecf72.js" as="script"><link rel="prefetch" href="/grocery_store/assets/js/10.666a773f.js"><link rel="prefetch" href="/grocery_store/assets/js/100.2b4d646e.js"><link rel="prefetch" href="/grocery_store/assets/js/101.de9d1a6c.js"><link rel="prefetch" href="/grocery_store/assets/js/102.85a31c0d.js"><link rel="prefetch" href="/grocery_store/assets/js/103.4d080f12.js"><link rel="prefetch" href="/grocery_store/assets/js/104.54bedf13.js"><link rel="prefetch" href="/grocery_store/assets/js/105.60e9e099.js"><link rel="prefetch" href="/grocery_store/assets/js/106.46204467.js"><link rel="prefetch" href="/grocery_store/assets/js/107.bd63530e.js"><link rel="prefetch" href="/grocery_store/assets/js/108.85a7fb4a.js"><link rel="prefetch" href="/grocery_store/assets/js/109.b3cce710.js"><link rel="prefetch" href="/grocery_store/assets/js/11.a878cb18.js"><link rel="prefetch" href="/grocery_store/assets/js/110.b71213ca.js"><link rel="prefetch" href="/grocery_store/assets/js/111.88e3c009.js"><link rel="prefetch" href="/grocery_store/assets/js/112.672c0e9c.js"><link rel="prefetch" href="/grocery_store/assets/js/113.9f626878.js"><link rel="prefetch" href="/grocery_store/assets/js/114.e971f677.js"><link rel="prefetch" href="/grocery_store/assets/js/115.32931221.js"><link rel="prefetch" href="/grocery_store/assets/js/116.7d7bb8e9.js"><link rel="prefetch" href="/grocery_store/assets/js/117.d1d64952.js"><link rel="prefetch" href="/grocery_store/assets/js/118.371e7dde.js"><link rel="prefetch" href="/grocery_store/assets/js/119.7187d3ac.js"><link rel="prefetch" href="/grocery_store/assets/js/12.7971495d.js"><link rel="prefetch" href="/grocery_store/assets/js/120.3f89d6c5.js"><link rel="prefetch" href="/grocery_store/assets/js/121.78a87a30.js"><link rel="prefetch" href="/grocery_store/assets/js/122.d2df534e.js"><link rel="prefetch" href="/grocery_store/assets/js/123.c95b11ab.js"><link rel="prefetch" href="/grocery_store/assets/js/124.0fb28081.js"><link rel="prefetch" href="/grocery_store/assets/js/125.ff76a45e.js"><link rel="prefetch" href="/grocery_store/assets/js/126.9328300b.js"><link rel="prefetch" href="/grocery_store/assets/js/127.a6a2f599.js"><link rel="prefetch" href="/grocery_store/assets/js/128.4f59b6b2.js"><link rel="prefetch" href="/grocery_store/assets/js/129.7ad23ac2.js"><link rel="prefetch" href="/grocery_store/assets/js/13.c108b008.js"><link rel="prefetch" href="/grocery_store/assets/js/130.ff450918.js"><link rel="prefetch" href="/grocery_store/assets/js/131.0c23ac4e.js"><link rel="prefetch" href="/grocery_store/assets/js/132.39985100.js"><link rel="prefetch" href="/grocery_store/assets/js/133.97d11e72.js"><link rel="prefetch" href="/grocery_store/assets/js/134.f7f5be44.js"><link rel="prefetch" href="/grocery_store/assets/js/135.8d032916.js"><link rel="prefetch" href="/grocery_store/assets/js/136.5f8428a0.js"><link rel="prefetch" href="/grocery_store/assets/js/137.68ec6b04.js"><link rel="prefetch" href="/grocery_store/assets/js/138.594feaf1.js"><link rel="prefetch" href="/grocery_store/assets/js/139.712936f1.js"><link rel="prefetch" href="/grocery_store/assets/js/140.e462485b.js"><link rel="prefetch" href="/grocery_store/assets/js/141.f7e3b64c.js"><link rel="prefetch" href="/grocery_store/assets/js/142.a1f358ef.js"><link rel="prefetch" href="/grocery_store/assets/js/143.7bd36db2.js"><link rel="prefetch" href="/grocery_store/assets/js/144.cfa08961.js"><link rel="prefetch" href="/grocery_store/assets/js/145.8d25c175.js"><link rel="prefetch" href="/grocery_store/assets/js/146.8205975e.js"><link rel="prefetch" href="/grocery_store/assets/js/147.cf326d2a.js"><link rel="prefetch" href="/grocery_store/assets/js/148.0d0d0e35.js"><link rel="prefetch" href="/grocery_store/assets/js/149.f913ee12.js"><link rel="prefetch" href="/grocery_store/assets/js/15.b2a89722.js"><link rel="prefetch" href="/grocery_store/assets/js/150.b5d4816c.js"><link rel="prefetch" href="/grocery_store/assets/js/151.3e654989.js"><link rel="prefetch" href="/grocery_store/assets/js/152.0ed89a9b.js"><link rel="prefetch" href="/grocery_store/assets/js/153.8e227ca1.js"><link rel="prefetch" href="/grocery_store/assets/js/154.a2831255.js"><link rel="prefetch" href="/grocery_store/assets/js/155.10ccf9ac.js"><link rel="prefetch" href="/grocery_store/assets/js/156.380d2724.js"><link rel="prefetch" href="/grocery_store/assets/js/157.c81733eb.js"><link rel="prefetch" href="/grocery_store/assets/js/158.cbfc3908.js"><link rel="prefetch" href="/grocery_store/assets/js/159.a6d3ae98.js"><link rel="prefetch" href="/grocery_store/assets/js/16.fd35c607.js"><link rel="prefetch" href="/grocery_store/assets/js/160.7255e3b5.js"><link rel="prefetch" href="/grocery_store/assets/js/161.904010dd.js"><link rel="prefetch" href="/grocery_store/assets/js/162.4dec98b6.js"><link rel="prefetch" href="/grocery_store/assets/js/163.37a5ff7f.js"><link rel="prefetch" href="/grocery_store/assets/js/164.88a4ed0a.js"><link rel="prefetch" href="/grocery_store/assets/js/165.e5de4c12.js"><link rel="prefetch" href="/grocery_store/assets/js/166.acb3ac67.js"><link rel="prefetch" href="/grocery_store/assets/js/167.922fe947.js"><link rel="prefetch" href="/grocery_store/assets/js/168.9b5decdc.js"><link rel="prefetch" href="/grocery_store/assets/js/169.774f7b4f.js"><link rel="prefetch" href="/grocery_store/assets/js/17.94989432.js"><link rel="prefetch" href="/grocery_store/assets/js/170.74cc7593.js"><link rel="prefetch" href="/grocery_store/assets/js/171.f22f02e1.js"><link rel="prefetch" href="/grocery_store/assets/js/172.795a7607.js"><link rel="prefetch" href="/grocery_store/assets/js/173.6a9852b2.js"><link rel="prefetch" href="/grocery_store/assets/js/174.24096d24.js"><link rel="prefetch" href="/grocery_store/assets/js/175.e1f80709.js"><link rel="prefetch" href="/grocery_store/assets/js/176.89e20247.js"><link rel="prefetch" href="/grocery_store/assets/js/177.90f78411.js"><link rel="prefetch" href="/grocery_store/assets/js/178.7cad688f.js"><link rel="prefetch" href="/grocery_store/assets/js/179.869c8720.js"><link rel="prefetch" href="/grocery_store/assets/js/18.dd69d970.js"><link rel="prefetch" href="/grocery_store/assets/js/180.c18e296f.js"><link rel="prefetch" href="/grocery_store/assets/js/19.e3521f6f.js"><link rel="prefetch" href="/grocery_store/assets/js/2.6f311729.js"><link rel="prefetch" href="/grocery_store/assets/js/20.cdd37c03.js"><link rel="prefetch" href="/grocery_store/assets/js/21.74481991.js"><link rel="prefetch" href="/grocery_store/assets/js/22.13aba632.js"><link rel="prefetch" href="/grocery_store/assets/js/23.faf985dd.js"><link rel="prefetch" href="/grocery_store/assets/js/24.7790407e.js"><link rel="prefetch" href="/grocery_store/assets/js/25.cc831358.js"><link rel="prefetch" href="/grocery_store/assets/js/26.5b918371.js"><link rel="prefetch" href="/grocery_store/assets/js/27.1fb985ed.js"><link rel="prefetch" href="/grocery_store/assets/js/28.4f194089.js"><link rel="prefetch" href="/grocery_store/assets/js/29.0e71c38a.js"><link rel="prefetch" href="/grocery_store/assets/js/30.9f05173d.js"><link rel="prefetch" href="/grocery_store/assets/js/31.5e341171.js"><link rel="prefetch" href="/grocery_store/assets/js/32.a550c1a0.js"><link rel="prefetch" href="/grocery_store/assets/js/33.8a828405.js"><link rel="prefetch" href="/grocery_store/assets/js/34.f7e62a92.js"><link rel="prefetch" href="/grocery_store/assets/js/35.711fbf92.js"><link rel="prefetch" href="/grocery_store/assets/js/36.b9fe8ec6.js"><link rel="prefetch" href="/grocery_store/assets/js/37.a924be53.js"><link rel="prefetch" href="/grocery_store/assets/js/38.e8f0d4cf.js"><link rel="prefetch" href="/grocery_store/assets/js/39.4cc4d0f7.js"><link rel="prefetch" href="/grocery_store/assets/js/4.2b8a6a17.js"><link rel="prefetch" href="/grocery_store/assets/js/40.39fd33ca.js"><link rel="prefetch" href="/grocery_store/assets/js/41.aa2d5c38.js"><link rel="prefetch" href="/grocery_store/assets/js/42.2e653320.js"><link rel="prefetch" href="/grocery_store/assets/js/43.60b064bc.js"><link rel="prefetch" href="/grocery_store/assets/js/44.b9efc4b4.js"><link rel="prefetch" href="/grocery_store/assets/js/45.9345a9b8.js"><link rel="prefetch" href="/grocery_store/assets/js/46.58671855.js"><link rel="prefetch" href="/grocery_store/assets/js/47.e8dced2f.js"><link rel="prefetch" href="/grocery_store/assets/js/48.623a8708.js"><link rel="prefetch" href="/grocery_store/assets/js/49.3da43528.js"><link rel="prefetch" href="/grocery_store/assets/js/5.41bb00f7.js"><link rel="prefetch" href="/grocery_store/assets/js/50.e8b509c0.js"><link rel="prefetch" href="/grocery_store/assets/js/51.57dea248.js"><link rel="prefetch" href="/grocery_store/assets/js/52.2a653b34.js"><link rel="prefetch" href="/grocery_store/assets/js/53.7e9a38b7.js"><link rel="prefetch" href="/grocery_store/assets/js/54.a6d6a228.js"><link rel="prefetch" href="/grocery_store/assets/js/55.6589895a.js"><link rel="prefetch" href="/grocery_store/assets/js/56.f2fcde50.js"><link rel="prefetch" href="/grocery_store/assets/js/57.8fbc4361.js"><link rel="prefetch" href="/grocery_store/assets/js/58.e5afed15.js"><link rel="prefetch" href="/grocery_store/assets/js/59.2c8ca963.js"><link rel="prefetch" href="/grocery_store/assets/js/6.31d3db0c.js"><link rel="prefetch" href="/grocery_store/assets/js/60.79a70c57.js"><link rel="prefetch" href="/grocery_store/assets/js/61.9fef88bd.js"><link rel="prefetch" href="/grocery_store/assets/js/62.e375e524.js"><link rel="prefetch" href="/grocery_store/assets/js/63.5952f2d6.js"><link rel="prefetch" href="/grocery_store/assets/js/64.2695a163.js"><link rel="prefetch" href="/grocery_store/assets/js/65.96a95c08.js"><link rel="prefetch" href="/grocery_store/assets/js/66.82c501b5.js"><link rel="prefetch" href="/grocery_store/assets/js/67.c3dfe33d.js"><link rel="prefetch" href="/grocery_store/assets/js/68.8d61e8ca.js"><link rel="prefetch" href="/grocery_store/assets/js/69.ffb2c059.js"><link rel="prefetch" href="/grocery_store/assets/js/7.390fea20.js"><link rel="prefetch" href="/grocery_store/assets/js/70.487b0cd7.js"><link rel="prefetch" href="/grocery_store/assets/js/71.698c9666.js"><link rel="prefetch" href="/grocery_store/assets/js/72.baf6aad0.js"><link rel="prefetch" href="/grocery_store/assets/js/73.a28c801a.js"><link rel="prefetch" href="/grocery_store/assets/js/74.fb3ba6d3.js"><link rel="prefetch" href="/grocery_store/assets/js/75.acb4412a.js"><link rel="prefetch" href="/grocery_store/assets/js/76.3bd634b6.js"><link rel="prefetch" href="/grocery_store/assets/js/77.db356fda.js"><link rel="prefetch" href="/grocery_store/assets/js/78.c7912e34.js"><link rel="prefetch" href="/grocery_store/assets/js/79.2144dc16.js"><link rel="prefetch" href="/grocery_store/assets/js/8.aee987bd.js"><link rel="prefetch" href="/grocery_store/assets/js/80.d6fbf3d8.js"><link rel="prefetch" href="/grocery_store/assets/js/81.e21a47d6.js"><link rel="prefetch" href="/grocery_store/assets/js/82.7f4636b3.js"><link rel="prefetch" href="/grocery_store/assets/js/83.440942f4.js"><link rel="prefetch" href="/grocery_store/assets/js/84.f0d9a8fe.js"><link rel="prefetch" href="/grocery_store/assets/js/85.39c6b930.js"><link rel="prefetch" href="/grocery_store/assets/js/86.75218340.js"><link rel="prefetch" href="/grocery_store/assets/js/87.b103ab9e.js"><link rel="prefetch" href="/grocery_store/assets/js/88.ac661b1d.js"><link rel="prefetch" href="/grocery_store/assets/js/89.92e470b3.js"><link rel="prefetch" href="/grocery_store/assets/js/9.ad4b2757.js"><link rel="prefetch" href="/grocery_store/assets/js/90.b2e04d90.js"><link rel="prefetch" href="/grocery_store/assets/js/91.8a00aaec.js"><link rel="prefetch" href="/grocery_store/assets/js/92.f7d023f2.js"><link rel="prefetch" href="/grocery_store/assets/js/93.9128c36a.js"><link rel="prefetch" href="/grocery_store/assets/js/94.6280de17.js"><link rel="prefetch" href="/grocery_store/assets/js/95.ea00692f.js"><link rel="prefetch" href="/grocery_store/assets/js/96.a140f30e.js"><link rel="prefetch" href="/grocery_store/assets/js/97.ea5254e3.js"><link rel="prefetch" href="/grocery_store/assets/js/98.9e168926.js"><link rel="prefetch" href="/grocery_store/assets/js/99.c5f861f8.js">
    <link rel="stylesheet" href="/grocery_store/assets/css/0.styles.892fb305.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/grocery_store/" class="home-link router-link-active"><!----> <span class="site-name">Lancezhange Vuepress Book</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/grocery_store/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/grocery_store/SUMMARY/" class="nav-link">
  Contents
</a></div><div class="nav-item"><a href="http://www.lancezhange.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Blog
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/grocery_store/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/grocery_store/SUMMARY/" class="nav-link">
  Contents
</a></div><div class="nav-item"><a href="http://www.lancezhange.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Blog
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/grocery_store/section4/" class="sidebar-link">数学基础</a></li><li><a href="/grocery_store/section4/basicmath.html" class="sidebar-link">数学基础知识 {ignore=true}</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/basicmath.html#线性代数" class="sidebar-link">线性代数</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/basicmath.html#概率" class="sidebar-link">概率</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/basicmath.html#抽象代数" class="sidebar-link">抽象代数</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/basicmath.html#复变函数" class="sidebar-link">复变函数</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/basicmath.html#初等数论" class="sidebar-link">初等数论</a></li></ul></li><li><a href="/grocery_store/section4/calculus.html" class="sidebar-link">数学分析 {ignore=ture}</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/calculus.html#微分" class="sidebar-link">微分</a></li></ul></li><li><a href="/grocery_store/section4/algebra.html" class="sidebar-link">代数</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#行列式和矩阵" class="sidebar-link">行列式和矩阵</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#零空间" class="sidebar-link">零空间</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#列空间" class="sidebar-link">列空间</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#秩定理" class="sidebar-link">秩定理</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#奇异值分解" class="sidebar-link">奇异值分解</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#对称矩阵的正交对角化" class="sidebar-link">对称矩阵的正交对角化</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#子空间基定理" class="sidebar-link">子空间基定理</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#行列式恒等式" class="sidebar-link">行列式恒等式</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#特征值" class="sidebar-link">特征值</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/algebra.html#相似阵" class="sidebar-link">相似阵</a></li></ul></li><li><a href="/grocery_store/section4/geometry.html" class="sidebar-link">几何</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/geometry.html#空间解析几何" class="sidebar-link">空间解析几何</a></li></ul></li><li><a href="/grocery_store/section4/probability.html" class="sidebar-link">概率 {ignore=true}</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/probability.html#基本理论" class="sidebar-link">基本理论</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/probability.html#常见概率题" class="sidebar-link">常见概率题</a></li></ul></li><li><a href="/grocery_store/section4/graphTheory.html" class="sidebar-link">图论 {ignore=true}</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/graphTheory.html#基础理论" class="sidebar-link">基础理论</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/graphTheory.html#常见问题和算法" class="sidebar-link">常见问题和算法</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/graphTheory.html#spectral-graph-theory" class="sidebar-link">Spectral graph theory</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/graphTheory.html#deepwalk" class="sidebar-link">DeepWalk</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/graphTheory.html#工具" class="sidebar-link">工具</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/graphTheory.html#参考" class="sidebar-link">参考</a></li></ul></li><li><a href="/grocery_store/section4/optimization.html" class="active sidebar-link">最优化 {ignore=true}</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/optimization.html#基础优化算法" class="sidebar-link">基础优化算法</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/optimization.html#凸优化方法" class="sidebar-link">凸优化方法</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/optimization.html#组合优化" class="sidebar-link">组合优化</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/optimization.html#在线优化-online-optimization" class="sidebar-link">在线优化 (Online Optimization)</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/optimization.html#非凸优化" class="sidebar-link">非凸优化</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/optimization.html#常用的一些检验函数" class="sidebar-link">常用的一些检验函数</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/optimization.html#参考" class="sidebar-link">参考</a></li></ul></li><li><a href="/grocery_store/section4/statistics.html" class="sidebar-link">统计基础 {ignore=true}</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/statistics.html#充分统计量" class="sidebar-link">充分统计量</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/statistics.html#极大似然-mle" class="sidebar-link">极大似然 MLE</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/statistics.html#statistical-power" class="sidebar-link">Statistical Power</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/statistics.html#jansen-不等式" class="sidebar-link">Jansen 不等式</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/statistics.html#分布生成" class="sidebar-link">分布生成</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/statistics.html#高维统计" class="sidebar-link">高维统计</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/statistics.html#相关性分析" class="sidebar-link">相关性分析</a></li></ul></li><li><a href="/grocery_store/section4/numerical_computation.html" class="sidebar-link">数值计算 {ignore=true}</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/numerical_computation.html#数值计算的稳定性" class="sidebar-link">数值计算的稳定性</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/numerical_computation.html#优化方法" class="sidebar-link">优化方法</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/numerical_computation.html#fast-fourier-transforms" class="sidebar-link">Fast Fourier Transforms</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/numerical_computation.html#曲线拟合和多项式插值" class="sidebar-link">曲线拟合和多项式插值</a></li></ul></li><li><a href="/grocery_store/section4/sampling.html" class="sidebar-link">采样 {ignore=true}</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/sampling.html#统计抽样理论" class="sidebar-link">统计抽样理论</a></li><li class="sidebar-sub-header"><a href="/grocery_store/section4/sampling.html#高维采样方法" class="sidebar-link">高维采样方法</a></li></ul></li><li><a href="/grocery_store/section4/mathProblems.html" class="sidebar-link">数学题</a></li><li><a href="/grocery_store/section4/math_tips.html" class="sidebar-link">数学问题</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/grocery_store/section4/math_tips.html#polya-计数" class="sidebar-link">Polya 计数</a></li></ul></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="最优化-ignore-true"><a href="#最优化-ignore-true" class="header-anchor">#</a> 最优化 {ignore=true}</h1> <p>[TOC]</p> <p>关于优化，有一点是极其重要的：<strong>永远没有一劳永逸、放之四海而皆准的最优化方法</strong>，虽然有一些通用的框架来做优化，但针对不同的函数还是有不同的特殊优化方法，所以，独特的观察和设计永远是必需的。</p> <h2 id="基础优化算法"><a href="#基础优化算法" class="header-anchor">#</a> 基础优化算法</h2> <p>可行集 D 的性质显然对优化问题的解影响巨大。一般情况下，我们至少假设 D 是连续的。
当 D 是一个凸多面体的时候，最优化问题就一定是线性规划的，这主要依赖了凸集中的任何一点都可以由顶点线性表出这个特征性质。对于线性规划问题，单纯形法----被认为是二十世纪最为重要的十个算法之一---提供了几乎完美的解决。</p> <p>当 f 不连续的时候，我们能做的也很有限，所以我们一般也至少假设 f 为连续函数。(有时甚至假设 f 可微)</p> <p>我们主要考虑三个问题：是否有最优解，解是否唯一以及怎样计算解</p> <h3 id="梯度下降法"><a href="#梯度下降法" class="header-anchor">#</a> 梯度下降法</h3> <p>梯度下降法是求解无约束最优化问题的一种常见方法，优点是实现简单。</p>
\theta ^ { t } = \theta ^ { t - 1 } + \Delta \theta \\\
\begin{align}
L \left( \theta ^ { t } \right) &amp;= L \left( \theta ^ { t - 1 } + \Delta \theta \right) \\\
&amp; \approx L \left( \theta ^ { t - 1 } \right) + L ^ { \prime } \left( \theta ^ { t - 1 } \right) \Delta \theta
\end{align}

<h4 id="参数更新方法"><a href="#参数更新方法" class="header-anchor">#</a> 参数更新方法</h4> <h5 id="bgd"><a href="#bgd" class="header-anchor">#</a> BGD</h5> <p>批量梯度下降: 算法在读取整个数据集后累加来计算损失函数的的梯度</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>−</mo><mo>=</mo><mi>η</mi><msub><mi mathvariant="normal">∇</mi><mrow><mi>w</mi></mrow></msub><mi>L</mi><mo>(</mo><mi>w</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">w - = \eta \nabla _ { w } L ( w )
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">−</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.03588em;">η</span><span class="mord"><span class="mord mathrm">∇</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit">L</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mclose">)</span></span></span></span></span></p> <h5 id="sgd"><a href="#sgd" class="header-anchor">#</a> SGD</h5> <p>随机梯度下降: 每读入一个数据都会立刻计算损失函数的梯度来更新参数．</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>−</mo><mo>=</mo><mi>η</mi><msub><mi mathvariant="normal">∇</mi><mrow><msub><mi>w</mi><mrow><mi>i</mi></mrow></msub></mrow></msub><mi>L</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>i</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">w - = \eta \nabla _ { w _ { i } } L \left( w _ { i } \right)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1.005em;vertical-align:-0.255em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">−</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.03588em;">η</span><span class="mord"><span class="mord mathrm">∇</span><span class="vlist"><span style="top:0.15000000000000002em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit">L</span><span class="minner displaystyle textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">)</span></span></span></span></span></span></p> <h5 id="mini-bgd"><a href="#mini-bgd" class="header-anchor">#</a> Mini-BGD</h5> <p>选择小批量数据进行梯度下降</p> <aside class="caution">
很多深度学习文献资料中说的 SGD，通常都是指 mini-batch 梯度下降
</aside> <h5 id="weight-decay"><a href="#weight-decay" class="header-anchor">#</a> weight decay</h5>
\boldsymbol { \theta } _ { t + 1 } = ( 1 - \lambda ) \boldsymbol { \theta } _ { t } - \alpha \nabla f _ { t } \left( \boldsymbol { \theta } _ { t } \right)

<h5 id="momentum"><a href="#momentum" class="header-anchor">#</a> Momentum</h5> <p>动量法</p> <p><a href="https://distill.pub/2017/momentum/" target="_blank" rel="noopener noreferrer">Why Momentum really works<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> by Distill, 写的像一篇优美的散文。</p> <blockquote><p>A lower bound, courtesy of Nesterov [5], states that momentum is, in a certain very narrow and technical sense, optimal. Now, this doesn’t mean it is the best algorithm for all functions in all circumstances. But it does satisfy some curiously beautiful mathematical properties which scratch a very human itch for perfection and closure. But more on that later. Let’s say this for now — momentum is an algorithm for the book.</p></blockquote> <p>SGDM： SGD with Momentum</p> <p><img src="/grocery_store/assets/img/2019-08-20-17-51-43.be2497b6.png" alt=""></p> <h5 id="nag"><a href="#nag" class="header-anchor">#</a> NAG</h5> <p>NAG（Nesterov accelerated gradient）: SGD with Nesterov Acceleration ， 基于 Nesterov 动量的算法</p> <h5 id="adagrad"><a href="#adagrad" class="header-anchor">#</a> AdaGrad</h5> <p>对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。</p> <p>AdaGrad 算法能够在训练中自动的对学习速率 α 进行调整，对于出现频率较低参数采用较大的 α 更新；相反，对于出现频率较高的参数采用较小的 α 更新。Adagrad 非常适合处理稀疏数据。很明显，AdaGrad 算法利用的是一阶导数。</p> <h5 id="rmsprop"><a href="#rmsprop" class="header-anchor">#</a> RMSprop</h5> <p>root mean square propagation</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>V</mi><mrow><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>β</mi><mrow><mn>2</mn></mrow></msub><mo>∗</mo><msub><mi>V</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mrow><mn>2</mn></mrow></msub><mo fence="true">)</mo></mrow><msubsup><mi>g</mi><mrow><mi>t</mi></mrow><mrow><mn>2</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex">V _ { t } = \beta _ { 2 } * V _ { t - 1 } + \left( 1 - \beta _ { 2 } \right) g _ { t } ^ { 2 }
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.8641079999999999em;"></span><span class="strut bottom" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.22222em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">∗</span><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.22222em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="minner displaystyle textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">)</span></span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.247em;margin-left:-0.03588em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span style="top:-0.4129999999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathrm">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p> <h5 id="adadelta"><a href="#adadelta" class="header-anchor">#</a> AdaDelta</h5> <h5 id="adam"><a href="#adam" class="header-anchor">#</a> Adam</h5> <p>名字派生自短语 <code>adaptive moments</code>
是对 RMSProp 优化器的更新</p> <p>把一阶动量和二阶动量都用起来</p> <p>无脑用 Adam 可不行！</p> <p><code>The Marginal Value of Adaptive Gradient Methods in Machine Learning</code></p> <blockquote><p>Despite the fact that our experimental evidence demonstrates that adaptive methods are not advantageous for machine learning, the Adam algorithm remains incredibly popular. We are not sure exactly as to why ……</p></blockquote> <p><code>On the Convergence of Adam and Beyond</code> 探讨了 Adam 算法的收敛性，通过反例证明了 Adam 在某些情况下可能会不收敛。</p> <h5 id="nadam"><a href="#nadam" class="header-anchor">#</a> Nadam</h5> <p><code>Nesterov + Adam = Nadam</code></p> <h5 id="nd-adam"><a href="#nd-adam" class="header-anchor">#</a> ND-Adam</h5> <p>Normalized Direction-preserving Adam</p> <h4 id="更新方法总结"><a href="#更新方法总结" class="header-anchor">#</a> 更新方法总结</h4> <p><img src="/grocery_store/assets/img/2019-06-17-17-47-09.5e845889.png" alt=""></p> <p>几乎每个参数优化更新方法，都是在优化这几步。</p> <p>对 SGD</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>g</mi><mrow><mi>t</mi></mrow></msub><mo separator="true">;</mo><msub><mi>V</mi><mrow><mi>t</mi></mrow></msub><mo>=</mo><msup><mi>I</mi><mrow><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">m _ { t } = g _ { t } ; V _ { t } = I ^ { 2 }
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.8641079999999999em;"></span><span class="strut bottom" style="height:1.0585479999999998em;vertical-align:-0.19444em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">m</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">;</span><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.22222em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathrm">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p> <p>对 SGDM</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>m</mi><mrow><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>β</mi><mrow><mn>1</mn></mrow></msub><mo>⋅</mo><msub><mi>m</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mrow><mn>1</mn></mrow></msub><mo fence="true">)</mo></mrow><mo>⋅</mo><msub><mi>g</mi><mrow><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">m _ { t } = \beta _ { 1 } \cdot m _ { t - 1 } + \left( 1 - \beta _ { 1 } \right) \cdot g _ { t }
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit">m</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">⋅</span><span class="mord"><span class="mord mathit">m</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="minner displaystyle textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">)</span></span><span class="mbin">⋅</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p> <p>一阶动量是各个时刻梯度方向的指数移动平均值，约等于最近<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mrow><mn>1</mn></mrow></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">1 / \left( 1 - \beta _ { 1 } \right)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">/</span><span class="minner textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord"><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05278em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">)</span></span></span></span></span> 个时刻的梯度向量和的平均值。</p> <p>也就是说，t 时刻的下降方向，不仅由当前点的梯度方向决定，而且由此前累积的下降方向决定。 \beta_1 的经验值为 0.9，这就意味着下降方向主要是此前累积的下降方向，并略微偏向当前时刻的下降方向。想象高速公路上汽车转弯，在高速向前的同时略微偏向，急转弯可是要出事的。</p> <p>NAG 在步骤 1，不计算当前位置的梯度方向，而是计算如果按照累积动量走了一步，那个时候的下降方向：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>g</mi><mrow><mi>t</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">∇</mi><mi>f</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi></mrow></msub><mo>−</mo><mi>α</mi><mo>⋅</mo><msub><mi>m</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mi mathvariant="normal">/</mi><msqrt><mrow><msub><mi>V</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow></msqrt><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">g _ { t } = \nabla f \left( w _ { t } - \alpha \cdot m _ { t - 1 } / \sqrt { V _ { t - 1 } } \right)
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:1.15em;"></span><span class="strut bottom" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">∇</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="minner displaystyle textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mbin">⋅</span><span class="mord"><span class="mord mathit">m</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">/</span><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.08137950000000005em;"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing size1">√</span></span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord displaystyle textstyle cramped"><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.22222em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">t</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span style="top:-0.8913795em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></span></p> <table><thead><tr><th>算法</th> <th>优点</th> <th>缺点</th></tr></thead> <tbody><tr><td>BGD</td> <td></td> <td>数据处理量大，导致梯度下降慢，不能在线更新；占内存</td></tr> <tr><td>SGD</td> <td></td> <td>降速度慢，而且可能会在沟壑的两边持续震荡，停留在一个局部最优点</td></tr> <tr><td>mini-BGD</td> <td></td> <td></td></tr></tbody></table> <table><tr><td><center><img src="/grocery_store/assets/img/opt2.5d5166a3.gif">animation</center></td> <td><center><img src="/grocery_store/assets/img/opt1.4a3b4a39.gif">animation </center></td></tr></table> <h3 id="牛顿法"><a href="#牛顿法" class="header-anchor">#</a> 牛顿法</h3> <p>二阶泰勒展开</p>
L \left( \theta ^ { t } \right) \approx L \left( \theta ^ { t - 1 } \right) + g \Delta \theta + h \frac { \Delta \theta ^ { 2 } } { 2 } \\\
可取 \Delta \theta = - \frac { g } { h } \\\
则 \theta ^ { t } = \theta ^ { t - 1 } + \Delta \theta = \theta ^ { t - 1 } - \frac { g } { h } \\\
推广到高维，则有  \theta ^ { t } = \theta ^ { t - 1 } - H ^ { - 1 } g

<h3 id="拟牛顿法"><a href="#拟牛顿法" class="header-anchor">#</a> 拟牛顿法</h3> <p>Quasi-Newton Methods</p> <p>海森矩阵的逆矩阵求解麻烦，近似之</p> <h3 id="共轭梯度法"><a href="#共轭梯度法" class="header-anchor">#</a> 共轭梯度法</h3> <p>Conjugate Gradient</p> <h3 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="header-anchor">#</a> 拉格朗日乘子法</h3> <p>针对有等式约束的</p> <h3 id="kkt-条件"><a href="#kkt-条件" class="header-anchor">#</a> KKT 条件</h3> <p>针对不等式约束的情形</p>
\begin{array} { c } { X = \operatorname { argmin } f ( X ) } \\\ { h _ { k } ( X ) = 0 ; k = 1,2 \ldots , n } \\\ { g _ { l } ( X ) \leq 0 ; l = 1,2 \ldots , m } \end{array}

<h3 id="启发式优化方法"><a href="#启发式优化方法" class="header-anchor">#</a> 启发式优化方法</h3> <p>包括经典的模拟退火方法、遗传算法、蚁群算法以及粒子群算法等等。</p> <p>还有一种特殊的优化算法被称之多目标优化算法，它主要针对同时优化多个目标（两个及两个以上）的优化问题，这方面比较经典的算法有 NSGAII 算法、MOEA/D 算法以及人工免疫算法等。</p> <h2 id="凸优化方法"><a href="#凸优化方法" class="header-anchor">#</a> 凸优化方法</h2> <p><a href="http://ruder.io/optimizing-gradient-descent/" target="_blank" rel="noopener noreferrer">An overview of gradient descent optimization algorithms<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h3 id="常用迭代方法"><a href="#常用迭代方法" class="header-anchor">#</a> 常用迭代方法</h3> <h4 id="l-bfgs"><a href="#l-bfgs" class="header-anchor">#</a> L-BFGS</h4> <p>L-BFGS 是基于牛顿优化算法的，牛顿优化算法使用的是二阶导数。</p> <h3 id="约束优化"><a href="#约束优化" class="header-anchor">#</a> 约束优化</h3> <h3 id="子模"><a href="#子模" class="header-anchor">#</a> 子模</h3> <p>submodular functions/亚模/次模函数</p> <p>参考 Jeffrey A. Bilmes 教授的 <a href="http://j.ee.washington.edu/~bilmes/classes/ee596b_spring_2014/" target="_blank" rel="noopener noreferrer">教程<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="http://arxiv.org/pdf/1311.2115v7.pdf" target="_blank" rel="noopener noreferrer">Fast large-scale optimization by unifying stochastic gradient and quasi-Newton methods<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="http://aria42.com/blog/2014/12/understanding-lbfgs/" target="_blank" rel="noopener noreferrer">Numerical Optimization: Understanding L-BFGS<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h3 id="admm-alternating-derection-method-of-multipliers"><a href="#admm-alternating-derection-method-of-multipliers" class="header-anchor">#</a> ADMM(alternating derection method of multipliers)</h3> <h3 id="proximal-algorithms"><a href="#proximal-algorithms" class="header-anchor">#</a> Proximal Algorithms</h3> <h2 id="组合优化"><a href="#组合优化" class="header-anchor">#</a> 组合优化</h2> <p>所谓组合优化，指的是在<strong>参数域为离散但是取值空间巨大的问题中搜索最值的过程</strong>。</p> <p>典型的组合优化问题包括：</p> <ul><li>TSP(旅行商问题)
给定 N 个城市的坐标，找到遍历这些城市的最短可行路径</li> <li></li></ul> <p>Neural Combinatorial Optimization with Reinforcement Learning.
参见<a href="https://github.com/higgsfield/np-hard-deep-reinforcement-learning/blob/master/Neural%20Combinatorial%20Optimization.ipynb" target="_blank" rel="noopener noreferrer">这个 notebook<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>那么问题来了，什么是神经组合优化？</p> <p>Nestrov</p> <h2 id="在线优化-online-optimization"><a href="#在线优化-online-optimization" class="header-anchor">#</a> 在线优化 (Online Optimization)</h2> <h3 id="ogd"><a href="#ogd" class="header-anchor">#</a> OGD</h3> <p>online gradient descent</p> <h3 id="截断梯度法-（tg-truncated-gradie"><a href="#截断梯度法-（tg-truncated-gradie" class="header-anchor">#</a> 截断梯度法 （TG, Truncated Gradie )</h3> <h3 id="前向后向切分（fobos-forward-backward-splitting）"><a href="#前向后向切分（fobos-forward-backward-splitting）" class="header-anchor">#</a> 前向后向切分（FOBOS, Forward-Backward Splitting）</h3> <h3 id="正则对偶平均（rda-regularized-dual-averagin"><a href="#正则对偶平均（rda-regularized-dual-averagin" class="header-anchor">#</a> 正则对偶平均（RDA, Regularized Dual Averagin</h3> <h3 id="ftrl"><a href="#ftrl" class="header-anchor">#</a> FTRL</h3> <h2 id="非凸优化"><a href="#非凸优化" class="header-anchor">#</a> 非凸优化</h2> <p>经常出现的一个假设条件 Lipschitz Condition.</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">∥</mi><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>−</mo><mi>f</mi><mo>(</mo><mi>y</mi><mo>)</mo><mi mathvariant="normal">∥</mi><mo>⩽</mo><mi>L</mi><mi mathvariant="normal">∥</mi><mi>x</mi><mo>−</mo><mi>y</mi><mi mathvariant="normal">∥</mi></mrow><annotation encoding="application/x-tex">\| f ( x ) - f ( y ) \| \leqslant L \| x - y \|
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathrm">∥</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord mathrm">∥</span><span class="mrel amsrm">⩽</span><span class="mord mathit">L</span><span class="mord mathrm">∥</span><span class="mord mathit">x</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathrm">∥</span></span></span></span></span></p> <h2 id="常用的一些检验函数"><a href="#常用的一些检验函数" class="header-anchor">#</a> 常用的一些检验函数</h2> <p>e.g.
<a href="https://dev.heuristiclab.com/trac.fcgi/wiki/Documentation/Reference/Test%20Functions" target="_blank" rel="noopener noreferrer">Ackley Function <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><img src="/grocery_store/assets/img/2019-05-14-22-21-34.00e23f38.png" alt=""></p> <h2 id="参考"><a href="#参考" class="header-anchor">#</a> 参考</h2> <ul><li><a href="http://www.cs.huji.ac.il/~shais/papers/OLsurvey.pdf" target="_blank" rel="noopener noreferrer">Online Learning and Online Convex Optimization<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> Foundations and Trends in
Machine Learning 系列之一本</li> <li>[ ] OPTutorial ，本地已下载，待读</li></ul></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/grocery_store/section4/graphTheory.html" class="prev">
        图论 {ignore=true}
      </a></span> <span class="next"><a href="/grocery_store/section4/statistics.html">
        统计基础 {ignore=true}
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----></div></div>
    <script src="/grocery_store/assets/js/app.47d3b9e2.js" defer></script><script src="/grocery_store/assets/js/3.e15ba04f.js" defer></script><script src="/grocery_store/assets/js/14.c8cecf72.js" defer></script>
  </body>
</html>
